 File "/Users/mayte/GitHub/BugPlusEngine/venv/lib/python3.10/site-packages/ray/tune/trainable/trainable.py", line 810, in restore_from_object
    self.restore(checkpoint_path)
  File "/Users/mayte/GitHub/BugPlusEngine/venv/lib/python3.10/site-packages/ray/tune/trainable/trainable.py", line 784, in restore
    self.load_checkpoint(to_load)
  File "/Users/mayte/GitHub/BugPlusEngine/venv/lib/python3.10/site-packages/ray/rllib/algorithms/algorithm.py", line 2092, in load_checkpoint
    self.__setstate__(checkpoint_data)
  File "/Users/mayte/GitHub/BugPlusEngine/venv/lib/python3.10/site-packages/ray/rllib/algorithms/algorithm.py", line 2502, in __setstate__
    self.workers.local_worker().set_state(state["worker"])
  File "/Users/mayte/GitHub/BugPlusEngine/venv/lib/python3.10/site-packages/ray/rllib/evaluation/rollout_worker.py", line 1697, in set_state
    self.policy_map[pid].set_state(policy_state)
  File "/Users/mayte/GitHub/BugPlusEngine/venv/lib/python3.10/site-packages/ray/rllib/policy/torch_mixins.py", line 108, in set_state
    super().set_state(state)
  File "/Users/mayte/GitHub/BugPlusEngine/venv/lib/python3.10/site-packages/ray/rllib/policy/torch_policy_v2.py", line 965, in set_state
    super().set_state(state)
  File "/Users/mayte/GitHub/BugPlusEngine/venv/lib/python3.10/site-packages/ray/rllib/policy/policy.py", line 1010, in set_state
    policy_spec = PolicySpec.deserialize(state["policy_spec"])
  File "/Users/mayte/GitHub/BugPlusEngine/venv/lib/python3.10/site-packages/ray/rllib/policy/policy.py", line 159, in deserialize
    observation_space=space_from_dict(spec["observation_space"]),
  File "/Users/mayte/GitHub/BugPlusEngine/venv/lib/python3.10/site-packages/ray/rllib/utils/serialization.py", line 283, in space_from_dict
    space.original_space = gym_space_from_dict(d["original_space"])
  File "/Users/mayte/GitHub/BugPlusEngine/venv/lib/python3.10/site-packages/ray/rllib/utils/serialization.py", line 276, in gym_space_from_dict
    return space_map[space_type](d)
  File "/Users/mayte/GitHub/BugPlusEngine/venv/lib/python3.10/site-packages/ray/rllib/utils/serialization.py", line 242, in _dict
    spaces = {k: gym_space_from_dict(sp) for k, sp in d["spaces"].items()}
  File "/Users/mayte/GitHub/BugPlusEngine/venv/lib/python3.10/site-packages/ray/rllib/utils/serialization.py", line 242, in <dictcomp>
    spaces = {k: gym_space_from_dict(sp) for k, sp in d["spaces"].items()}
  File "/Users/mayte/GitHub/BugPlusEngine/venv/lib/python3.10/site-packages/ray/rllib/utils/serialization.py", line 276, in gym_space_from_dict
    return space_map[space_type](d)
  File "/Users/mayte/GitHub/BugPlusEngine/venv/lib/python3.10/site-packages/ray/rllib/utils/serialization.py", line 226, in _multi_binary
    return gym.spaces.MultiBinary(**__common(d))
TypeError: MultiBinary.__init__() got an unexpected keyword argument 'dtype'
_

________________________
2. Versuch:

2023-04-14 18:18:12,759 INFO worker.py:1553 -- Started a local Ray instance.
(_WandbLoggingActor pid=3228) wandb: Currently logged in as: misssophie (bugplus). Use `wandb login --relogin` to force relogin
(_WandbLoggingActor pid=3228) wandb: wandb version 0.14.2 is available!  To upgrade, please run:
(_WandbLoggingActor pid=3228) wandb:  $ pip install wandb --upgrade
(_WandbLoggingActor pid=3228) wandb: Tracking run with wandb version 0.13.10
(_WandbLoggingActor pid=3228) wandb: Run data is saved locally in /Users/mayte/GitHub/BugPlusEngine/result_PPO_4_edges_action_clipping/PPO/PPO_BugPlus_f73a6_00000_0_2023-04-14_18-18-18/wandb/run-20230414_181825-f73a6_00000
(_WandbLoggingActor pid=3228) wandb: Run `wandb offline` to turn off syncing.
(_WandbLoggingActor pid=3228) wandb: Syncing run PPO_BugPlus_f73a6_00000
(_WandbLoggingActor pid=3228) wandb: ‚≠êÔ∏è View project at https://wandb.ai/bugplus/BugsPlus
(_WandbLoggingActor pid=3228) wandb: üöÄ View run at https://wandb.ai/bugplus/BugsPlus/runs/f73a6_00000
(PPO pid=3226) 2023-04-14 18:18:27,461  WARNING algorithm_config.py:596 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.
(PPO pid=3226) 2023-04-14 18:18:28,517  INFO algorithm.py:506 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.
(RolloutWorker pid=3290) 2023-04-14 18:18:38,160        WARNING env.py:156 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.
(RolloutWorker pid=3290) 2023-04-14 18:18:38,161        WARNING env.py:166 -- Your env reset() method appear
2023-04-15 00:45:43,675 INFO worker.py:1553 -- Started a local Ray instance.
2023-04-15 00:45:48,135 INFO trial_runner.py:783 -- Using following checkpoint to resume: /Users/mayte/GitHub/BugPlusEngine/result_PPO_4_edges_action_clipping/PPO/experiment_state-2023-04-14_18-18-17.json
2023-04-15 00:45:48,136 WARNING trial_runner.py:788 -- Attempting to resume experiment from /Users/mayte/GitHub/BugPlusEngine/result_PPO_4_edges_action_clipping/PPO. This will ignore any new changes to the specification.
2023-04-15 00:45:48,141 INFO tune.py:735 -- TrialRunner resumed, ignoring new add_experiment but updating trial resources.
(_WandbLoggingActor pid=35804) wandb: Currently logged in as: misssophie (bugplus). Use `wandb login --relogin` to force relogin
(_WandbLoggingActor pid=35804) wandb: wandb version 0.14.2 is available!  To upgrade, please run:
(_WandbLoggingActor pid=35804) wandb:  $ pip install wandb --upgrade
(_WandbLoggingActor pid=35804) wandb: Tracking run with wandb version 0.13.10
(_WandbLoggingActor pid=35804) wandb: Run data is saved locally in /Users/mayte/GitHub/BugPlusEngine/result_PPO_4_edges_action_clipping/PPO/PPO_BugPlus_f73a6_00000_0_2023-04-14_18-18-18/wandb/run-20230415_004555-f73a6_00000
(_WandbLoggingActor pid=35804) wandb: Run `wandb offline` to turn off syncing.
(_WandbLoggingActor pid=35804) wandb: Syncing run PPO_BugPlus_f73a6_00000
(_WandbLoggingActor pid=35804) wandb: ‚≠êÔ∏è View project at https://wandb.ai/bugplus/BugsPlus
(_WandbLoggingActor pid=35804) wandb: üöÄ View run at https://wandb.ai/bugplus/BugsPlus/runs/f73a6_00000
(PPO pid=35802) 2023-04-15 00:45:58,817 WARNING algorithm_config.py:596 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.
(PPO pid=35802) 2023-04-15 00:45:59,704 INFO algorithm.py:506 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.
(RolloutWorker pid=35847) 2023-04-15 00:46:08,298       WARNING env.py:156 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.
(RolloutWorker pid=35847) 2023-04-15 00:46:08,298       WARNING env.py:166 -- Your env reset() method appears to take 'seed' or 'return_info' arguments. Note that these are not yet supported in RLlib. Seeding will take place using 'env.seed()' and the info dict will not be returned from reset.
(PPO pid=35802) 2023-04-15 00:46:08,613 WARNING util.py:67 -- Install gputil for GPU system monitoring.
2023-04-15 00:46:08,718 ERROR trial_runner.py:1062 -- Trial PPO_BugPlus_f73a6_00000: Error processing event.
ray.exceptions.RayTaskError(TypeError): ray::PPO.restore_from_object() (pid=35802, ip=127.0.0.1, repr=PPO)
  File "/Users/mayte/GitHub/BugPlusEngine/venv/lib/python3.10/site-packages/ray/tune/trainable/trainable.py", line 810, in restore_from_object
    self.restore(checkpoint_path)
  File "/Users/mayte/GitHub/BugPlusEngine/venv/lib/python3.10/site-packages/ray/tune/trainable/trainable.py", line 784, in restore
    self.load_checkpoint(to_load)
  File "/Users/mayte/GitHub/BugPlusEngine/venv/lib/python3.10/site-packages/ray/rllib/algorithms/algorithm.py", line 2092, in load_checkpoint
    self.__setstate__(checkpoint_data)
  File "/Users/mayte/GitHub/BugPlusEngine/venv/lib/python3.10/site-packages/ray/rllib/algorithms/algorithm.py", line 2502, in __setstate__
    self.workers.local_worker().set_state(state["worker"])
  File "/Users/mayte/GitHub/BugPlusEngine/venv/lib/python3.10/site-packages/ray/rllib/evaluation/rollout_worker.py", line 1697, in set_state
    self.policy_map[pid].set_state(policy_state)
  File "/Users/mayte/GitHub/BugPlusEngine/venv/lib/python3.10/site-packages/ray/rllib/policy/torch_mixins.py", line 108, in set_state
    super().set_state(state)
  File "/Users/mayte/GitHub/BugPlusEngine/venv/lib/python3.10/site-packages/ray/rllib/policy/torch_policy_v2.py", line 965, in set_state
    super().set_state(state)
  File "/Users/mayte/GitHub/BugPlusEngine/venv/lib/python3.10/site-packages/ray/rllib/policy/policy.py", line 1010, in set_state
2023-04-15 00:49:42,845 INFO worker.py:1553 -- Started a local Ray instance.
2023-04-15 00:49:47,442 INFO trial_runner.py:783 -- Using following checkpoint to resume: /Users/mayte/GitHub/BugPlusEngine/result_PPO_4_edges_action_clipping/PPO/experiment_state-2023-04-15_00-45-48.json
2023-04-15 00:49:47,443 WARNING trial_runner.py:788 -- Attempting to resume experiment from /Users/mayte/GitHub/BugPlusEngine/result_PPO_4_edges_action_clipping/PPO. This will ignore any new changes to the specification.
2023-04-15 00:49:47,449 INFO tune.py:735 -- TrialRunner resumed, ignoring new add_experiment but updating trial resources.
Traceback (most recent call last):
  File "/Users/mayte/GitHub/BugPlusEngine/src/agent_dqn_and_ppo/ppo_action_clipping_reloading.py", line 27, in <module>
    tune.run("PPO", 
  File "/Users/mayte/GitHub/BugPlusEngine/venv/lib/python3.10/site-packages/ray/tune/tune.py", line 792, in run
    raise TuneError("Trials did not complete", incomplete_trials)
ray.tune.error.TuneError: ('Trials did not complete', [PPO_BugPlus_f73a6_00000])
(venv) mayte@Maytes-MacBook-Pro BugPlusEngine % 