{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load librabies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aaronsteiner/Documents/GitHub/BugPlusEngine/env/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import dgl.function as fn\n",
    "import torch.optim as optim\n",
    "import dgl\n",
    "import random\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "import itertools"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the graph and the deleted edge information from the file\n",
    "with open(\"../../graphs_and_deleted_edges.pickle\", \"rb\") as f:\n",
    "    all_graphs = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph(num_nodes=3, num_edges=12,\n",
      "      ndata_schemes={'features': Scheme(shape=(6,), dtype=torch.float32)}\n",
      "      edata_schemes={'edge_features': Scheme(shape=(3,), dtype=torch.int64)})\n"
     ]
    }
   ],
   "source": [
    "print(all_graphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split edge set for training and testing\n",
    "g = all_graphs\n",
    "u, v = g.edges()\n",
    "\n",
    "eids = np.arange(g.number_of_edges())\n",
    "eids = np.random.permutation(eids)\n",
    "test_size = 1\n",
    "train_size = g.number_of_edges() - test_size\n",
    "test_pos_u, test_pos_v = u[eids[:test_size]], v[eids[:test_size]]\n",
    "train_pos_u, train_pos_v = u[eids[test_size:]], v[eids[test_size:]]\n",
    "\n",
    "# Find all negative edges and split them for training and testing\n",
    "adj = sp.coo_matrix((np.ones(len(u)), (u.numpy(), v.numpy())))\n",
    "adj_neg = 1 - adj.todense() - np.eye(g.number_of_nodes())\n",
    "neg_u, neg_v = np.where(adj_neg != 0)\n",
    "\n",
    "neg_eids = np.random.choice(len(neg_u), g.number_of_edges())\n",
    "test_neg_u, test_neg_v = neg_u[neg_eids[:test_size]], neg_v[neg_eids[:test_size]]\n",
    "train_neg_u, train_neg_v = neg_u[neg_eids[test_size:]], neg_v[neg_eids[test_size:]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_g = dgl.remove_edges(g, eids[:test_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the edge feature representation module\n",
    "class EdgeModule(nn.Module):\n",
    "    def __init__(self, in_feats, hidden_size):\n",
    "        super(EdgeModule, self).__init__()\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(in_feats, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "        )\n",
    "\n",
    "    def forward(self, edges):\n",
    "        return self.mlp(edges.data[\"edge_features\"])\n",
    "\n",
    "# initialize the edge feature module\n",
    "edge_module = EdgeModule(in_feats=3, hidden_size=64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dgl.nn import SAGEConv\n",
    "\n",
    "# ----------- 2. create model -------------- #\n",
    "# build a two-layer GraphSAGE model\n",
    "class GraphSAGE(nn.Module):\n",
    "    def __init__(self, in_feats, h_feats):\n",
    "        super(GraphSAGE, self).__init__()\n",
    "        self.conv1 = SAGEConv(in_feats, h_feats, 'mean')\n",
    "        self.conv2 = SAGEConv(h_feats, h_feats, 'mean')\n",
    "\n",
    "    def forward(self, g, in_feat):\n",
    "        h = self.conv1(g, in_feat)\n",
    "        h = F.relu(h)\n",
    "        h = self.conv2(g, h)\n",
    "        return h\n",
    "    \n",
    "class EdgePredictionHead(nn.Module):\n",
    "    def __init__(self, h_feats, out_feats):\n",
    "        super(EdgePredictionHead, self).__init__()\n",
    "        self.fc = nn.Linear(2 * h_feats, out_feats)\n",
    "\n",
    "    def forward(self, g, h):\n",
    "        # calculate source and destination features\n",
    "        src_feat = h[g.srcnodes()]\n",
    "        dst_feat = h[g.dstnodes()]\n",
    "        # concatenate the source and destination features\n",
    "        edge_feat = torch.cat([src_feat, dst_feat], dim=1)\n",
    "        return self.fc(edge_feat)\n",
    "\n",
    "# build the final model\n",
    "model = nn.Sequential(GraphSAGE(in_feats=6, h_feats=64), EdgePredictionHead(h_feats=3, out_feats=32))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pos_g = dgl.graph((train_pos_u, train_pos_v), num_nodes=g.number_of_nodes())\n",
    "train_pos_g.edata[\"edge_features\"] = torch.ones(train_pos_u.shape[0], 3)\n",
    "\n",
    "train_neg_g = dgl.graph((train_neg_u, train_neg_v), num_nodes=g.number_of_nodes())\n",
    "train_neg_g.edata[\"edge_features\"] = torch.ones(train_neg_u.shape[0], 3)\n",
    "\n",
    "test_pos_g = dgl.graph((test_pos_u, test_pos_v), num_nodes=g.number_of_nodes())\n",
    "test_pos_g.edata[\"edge_features\"] = torch.ones(test_pos_u.shape[0], 3)\n",
    "\n",
    "test_neg_g = dgl.graph((test_neg_u, test_neg_v), num_nodes=g.number_of_nodes())\n",
    "test_neg_g.edata[\"edge_features\"] = torch.ones(test_neg_u.shape[0], 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dgl.function as fn\n",
    "\n",
    "class DotPredictor(nn.Module):\n",
    "    def forward(self, g, h):\n",
    "        with g.local_scope():\n",
    "            g.ndata['h'] = h\n",
    "            # Compute a new edge feature named 'score' by a dot-product between the\n",
    "            # source node feature 'h' and destination node feature 'h'.\n",
    "            g.apply_edges(fn.u_dot_v('h', 'h', 'score'))\n",
    "            # u_dot_v returns a 1-element vector for each edge so you need to squeeze it.\n",
    "            return g.edata['score'][:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = GraphSAGE(6, 16)\n",
    "# You can replace DotPredictor with MLPPredictor.\n",
    "#pred = MLPPredictor(16)\n",
    "pred = DotPredictor()\n",
    "\n",
    "def compute_loss(pos_score, neg_score):\n",
    "    scores = torch.cat([pos_score, neg_score])\n",
    "    labels = torch.cat([torch.ones(pos_score.shape[0]), torch.zeros(neg_score.shape[0])])\n",
    "    return F.binary_cross_entropy_with_logits(scores, labels)\n",
    "\n",
    "def compute_auc(pos_score, neg_score):\n",
    "    scores = torch.cat([pos_score, neg_score]).numpy()\n",
    "    labels = torch.cat(\n",
    "        [torch.ones(pos_score.shape[0]), torch.zeros(neg_score.shape[0])]).numpy()\n",
    "    return roc_auc_score(labels, scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'edge_features': tensor([[3, 3, 0],\n",
      "        [2, 2, 0],\n",
      "        [4, 4, 1],\n",
      "        [4, 4, 1],\n",
      "        [0, 0, 1],\n",
      "        [0, 0, 1],\n",
      "        [5, 5, 0],\n",
      "        [3, 5, 0],\n",
      "        [2, 5, 0],\n",
      "        [4, 0, 1],\n",
      "        [1, 1, 1],\n",
      "        [1, 1, 1]])}\n",
      "{'edge_features': tensor([[3, 3, 0],\n",
      "        [2, 2, 0],\n",
      "        [4, 4, 1],\n",
      "        [0, 0, 1],\n",
      "        [0, 0, 1],\n",
      "        [5, 5, 0],\n",
      "        [3, 5, 0],\n",
      "        [2, 5, 0],\n",
      "        [4, 0, 1],\n",
      "        [1, 1, 1],\n",
      "        [1, 1, 1]])}\n"
     ]
    }
   ],
   "source": [
    "print(all_graphs.edata)\n",
    "print(train_g.edata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'edge_features': tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]])}\n"
     ]
    }
   ],
   "source": [
    "print(train_pos_g.edata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "tensor([[ -929.7772,  -439.4871,  -611.1336,  -504.5811,   985.9515, -1352.3868,\n          -572.0422,   -80.4514,   708.3521,  1500.2485, -1062.7419,   584.3625,\n            62.9555, -1210.4502,    39.4332,     6.2775,   456.4863,  1304.8599,\n          1098.5679,  -413.2629,  -206.8904,  1294.6311,   104.2672,   380.7736,\n         -1924.0911,   202.8310,   920.3375, -1583.1564,  -120.0067,  1333.7421,\n          -716.2066, -1609.7782,  1116.8284,   189.1378, -1387.1909,  -592.5045,\n          1654.8821,  -368.1522,  -843.9202,   184.1393, -1311.3763,   802.1870,\n           714.5663,  -563.9583,  2794.1865, -2189.1594,  -344.3263, -1466.5177,\n            17.8305,  -384.9168,   586.9098, -1317.5717,   605.0861,  -747.1750,\n           462.0277,   642.3690,   139.8837, -1462.4358,  -893.5225, -1086.5804,\n         -1099.9971,   767.9631,  -399.1743,   264.2786],\n        [-1156.9180,    51.2558,   135.7433,  -303.1718,   914.8538, -1167.0736,\n          -378.4260,  -109.4861,  -320.8781,  1786.3391,  -256.1962,   140.5762,\n          -551.1962, -1793.3883,   296.0497,   477.2408,   913.3241,  2223.3877,\n          1026.1589,  -263.1776,   667.8753,   785.7402,    32.2801,   380.7964,\n         -1251.7607,   -50.3449,  1382.3224,  -946.1035,  -563.7194,   669.6123,\n          -414.5139, -1606.7959,    11.9010,   265.5717, -1055.2371,  -441.2202,\n          1243.6409,  -104.4527,  -603.9701,   266.9942, -1363.5756,   679.5348,\n           522.7903, -1040.3112,  2202.3303, -1802.0012,   571.7948, -1353.2537,\n           285.3437,  -278.1751,    87.4684,  -708.5936,  -180.4102,  -762.2383,\n           268.2186,    47.9887,   318.7112, -2139.3472,  -661.3098, -1191.2706,\n          -905.9852,   498.9993, -1382.5063,   508.1679],\n        [-1103.2584,   101.7638,    29.3093,   -34.4232,    92.5906,  -429.1176,\n          -982.3353,   111.6561,  -190.1467,  2236.4387,  -374.1266,  -102.0894,\n          -877.2246, -1401.3646,   369.8842,   183.8988,   967.7378,  2361.8420,\n           968.9070,  -298.6047,   737.6312,   766.1187,  -152.4131,   393.8352,\n         -1307.1805,  -832.2983,   771.8021,  -910.7532,  -250.2669,   531.7551,\n          -440.8855, -1147.4937,  -487.6537,   319.6133, -1126.8162, -1158.5282,\n           797.3972,   429.8589,  -843.3727,   187.7967, -1295.6335,  -165.2075,\n            97.9175,  -972.6052,  1955.4595, -1837.7422,  -207.3181,  -885.6255,\n           348.6840,  -178.3277,   276.6996,  -425.4726,  -548.9712,  -149.3974,\n           384.2936,   161.5435,  -166.1632, -2317.0410,  -120.5224, -1288.8203,\n          -882.6201,   396.0359, -2245.3330,   196.8366]],\n       grad_fn=<AddBackward0>)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[46], line 37\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[39mfor\u001b[39;00m e \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m2_000\u001b[39m):\n\u001b[1;32m     35\u001b[0m     \u001b[39m# Forward\u001b[39;00m\n\u001b[1;32m     36\u001b[0m     h \u001b[39m=\u001b[39m model(train_g, train_g\u001b[39m.\u001b[39mndata[\u001b[39m\"\u001b[39m\u001b[39mfeatures\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[0;32m---> 37\u001b[0m     pos_score \u001b[39m=\u001b[39m pred(train_pos_g, h, train_pos_g\u001b[39m.\u001b[39;49medata[\u001b[39m\"\u001b[39;49m\u001b[39medge_features\u001b[39;49m\u001b[39m\"\u001b[39;49m])\n\u001b[1;32m     38\u001b[0m     neg_score \u001b[39m=\u001b[39m pred(train_neg_g, h, train_neg_g\u001b[39m.\u001b[39medata[\u001b[39m\"\u001b[39m\u001b[39medge_features\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[1;32m     39\u001b[0m     loss \u001b[39m=\u001b[39m compute_loss(pos_score, neg_score)\n",
      "File \u001b[0;32m~/Documents/GitHub/BugPlusEngine/env/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[46], line 7\u001b[0m, in \u001b[0;36mEdgePredictor.forward\u001b[0;34m(self, g, h, edge_feat)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, g, h, edge_feat):\n\u001b[0;32m----> 7\u001b[0m     h_g \u001b[39m=\u001b[39m dgl\u001b[39m.\u001b[39;49mmean_nodes(g, h)\n\u001b[1;32m      8\u001b[0m     h_g \u001b[39m=\u001b[39m h_g\u001b[39m.\u001b[39mrepeat(g\u001b[39m.\u001b[39mnumber_of_edges(), \u001b[39m1\u001b[39m)\n\u001b[1;32m      9\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfc(torch\u001b[39m.\u001b[39mcat([h_g, edge_feat], dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m))\n",
      "File \u001b[0;32m~/Documents/GitHub/BugPlusEngine/env/lib/python3.10/site-packages/dgl/readout.py:198\u001b[0m, in \u001b[0;36mmean_nodes\u001b[0;34m(graph, feat, weight, ntype)\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmean_nodes\u001b[39m(graph, feat, weight\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m, ntype\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    192\u001b[0m     \u001b[39m\"\"\"Syntax sugar for ``dgl.readout_nodes(graph, feat, weight, ntype=ntype, op='mean')``.\u001b[39;00m\n\u001b[1;32m    193\u001b[0m \n\u001b[1;32m    194\u001b[0m \u001b[39m    See Also\u001b[39;00m\n\u001b[1;32m    195\u001b[0m \u001b[39m    --------\u001b[39;00m\n\u001b[1;32m    196\u001b[0m \u001b[39m    readout_nodes\u001b[39;00m\n\u001b[1;32m    197\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 198\u001b[0m     \u001b[39mreturn\u001b[39;00m readout_nodes(graph, feat, weight, ntype\u001b[39m=\u001b[39;49mntype, op\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mmean\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[0;32m~/Documents/GitHub/BugPlusEngine/env/lib/python3.10/site-packages/dgl/readout.py:85\u001b[0m, in \u001b[0;36mreadout_nodes\u001b[0;34m(graph, feat, weight, op, ntype)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mreadout_nodes\u001b[39m(graph, feat, weight\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m, op\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39msum\u001b[39m\u001b[39m'\u001b[39m, ntype\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m     14\u001b[0m     \u001b[39m\"\"\"Generate a graph-level representation by aggregating node features\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[39m    :attr:`feat`.\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[39m    readout_edges\u001b[39;00m\n\u001b[1;32m     84\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 85\u001b[0m     x \u001b[39m=\u001b[39m graph\u001b[39m.\u001b[39;49mnodes[ntype]\u001b[39m.\u001b[39;49mdata[feat]\n\u001b[1;32m     86\u001b[0m     \u001b[39mif\u001b[39;00m weight \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     87\u001b[0m         x \u001b[39m=\u001b[39m x \u001b[39m*\u001b[39m graph\u001b[39m.\u001b[39mnodes[ntype]\u001b[39m.\u001b[39mdata[weight]\n",
      "File \u001b[0;32m~/Documents/GitHub/BugPlusEngine/env/lib/python3.10/site-packages/dgl/view.py:73\u001b[0m, in \u001b[0;36mHeteroNodeDataView.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[39mreturn\u001b[39;00m ret\n\u001b[1;32m     72\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 73\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_graph\u001b[39m.\u001b[39;49m_get_n_repr(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_ntid, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_nodes)[key]\n",
      "File \u001b[0;32m~/Documents/GitHub/BugPlusEngine/env/lib/python3.10/site-packages/dgl/frame.py:622\u001b[0m, in \u001b[0;36mFrame.__getitem__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    609\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__getitem__\u001b[39m(\u001b[39mself\u001b[39m, name):\n\u001b[1;32m    610\u001b[0m     \u001b[39m\"\"\"Return the column of the given name.\u001b[39;00m\n\u001b[1;32m    611\u001b[0m \n\u001b[1;32m    612\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    620\u001b[0m \u001b[39m        Column data.\u001b[39;00m\n\u001b[1;32m    621\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 622\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_columns[name]\u001b[39m.\u001b[39mdata\n",
      "\u001b[0;31mKeyError\u001b[0m: tensor([[ -929.7772,  -439.4871,  -611.1336,  -504.5811,   985.9515, -1352.3868,\n          -572.0422,   -80.4514,   708.3521,  1500.2485, -1062.7419,   584.3625,\n            62.9555, -1210.4502,    39.4332,     6.2775,   456.4863,  1304.8599,\n          1098.5679,  -413.2629,  -206.8904,  1294.6311,   104.2672,   380.7736,\n         -1924.0911,   202.8310,   920.3375, -1583.1564,  -120.0067,  1333.7421,\n          -716.2066, -1609.7782,  1116.8284,   189.1378, -1387.1909,  -592.5045,\n          1654.8821,  -368.1522,  -843.9202,   184.1393, -1311.3763,   802.1870,\n           714.5663,  -563.9583,  2794.1865, -2189.1594,  -344.3263, -1466.5177,\n            17.8305,  -384.9168,   586.9098, -1317.5717,   605.0861,  -747.1750,\n           462.0277,   642.3690,   139.8837, -1462.4358,  -893.5225, -1086.5804,\n         -1099.9971,   767.9631,  -399.1743,   264.2786],\n        [-1156.9180,    51.2558,   135.7433,  -303.1718,   914.8538, -1167.0736,\n          -378.4260,  -109.4861,  -320.8781,  1786.3391,  -256.1962,   140.5762,\n          -551.1962, -1793.3883,   296.0497,   477.2408,   913.3241,  2223.3877,\n          1026.1589,  -263.1776,   667.8753,   785.7402,    32.2801,   380.7964,\n         -1251.7607,   -50.3449,  1382.3224,  -946.1035,  -563.7194,   669.6123,\n          -414.5139, -1606.7959,    11.9010,   265.5717, -1055.2371,  -441.2202,\n          1243.6409,  -104.4527,  -603.9701,   266.9942, -1363.5756,   679.5348,\n           522.7903, -1040.3112,  2202.3303, -1802.0012,   571.7948, -1353.2537,\n           285.3437,  -278.1751,    87.4684,  -708.5936,  -180.4102,  -762.2383,\n           268.2186,    47.9887,   318.7112, -2139.3472,  -661.3098, -1191.2706,\n          -905.9852,   498.9993, -1382.5063,   508.1679],\n        [-1103.2584,   101.7638,    29.3093,   -34.4232,    92.5906,  -429.1176,\n          -982.3353,   111.6561,  -190.1467,  2236.4387,  -374.1266,  -102.0894,\n          -877.2246, -1401.3646,   369.8842,   183.8988,   967.7378,  2361.8420,\n           968.9070,  -298.6047,   737.6312,   766.1187,  -152.4131,   393.8352,\n         -1307.1805,  -832.2983,   771.8021,  -910.7532,  -250.2669,   531.7551,\n          -440.8855, -1147.4937,  -487.6537,   319.6133, -1126.8162, -1158.5282,\n           797.3972,   429.8589,  -843.3727,   187.7967, -1295.6335,  -165.2075,\n            97.9175,  -972.6052,  1955.4595, -1837.7422,  -207.3181,  -885.6255,\n           348.6840,  -178.3277,   276.6996,  -425.4726,  -548.9712,  -149.3974,\n           384.2936,   161.5435,  -166.1632, -2317.0410,  -120.5224, -1288.8203,\n          -882.6201,   396.0359, -2245.3330,   196.8366]],\n       grad_fn=<AddBackward0>)"
     ]
    }
   ],
   "source": [
    "class EdgePredictor(nn.Module):\n",
    "    def __init__(self, in_feats, edge_feats):\n",
    "        super(EdgePredictor, self).__init__()\n",
    "        self.fc = nn.Linear(in_feats + edge_feats, 1)\n",
    "\n",
    "    def forward(self, g, h, edge_feat):\n",
    "        h_g = dgl.mean_nodes(g, h)\n",
    "        h_g = h_g.repeat(g.number_of_edges(), 1)\n",
    "        return self.fc(torch.cat([h_g, edge_feat], dim=1))\n",
    "\n",
    "class GraphSAGE(nn.Module):\n",
    "    def __init__(self, in_feats, h_feats):\n",
    "        super(GraphSAGE, self).__init__()\n",
    "        self.conv1 = SAGEConv(in_feats, h_feats, 'mean')\n",
    "        self.conv2 = SAGEConv(h_feats, h_feats, 'mean')\n",
    "\n",
    "    def forward(self, g, in_feat):\n",
    "        h = self.conv1(g, in_feat)\n",
    "        h = F.relu(h)\n",
    "        h = self.conv2(g, h)\n",
    "        return h\n",
    "\n",
    "# Edge predictor\n",
    "pred = EdgePredictor(64, 3)\n",
    "\n",
    "# GraphSAGE model\n",
    "model = GraphSAGE(6, 64)\n",
    "\n",
    "\n",
    "# Optimizer\n",
    "optimizer = torch.optim.Adam(itertools.chain(model.parameters(), pred.parameters()), lr=0.01)\n",
    "\n",
    "# Training loop\n",
    "for e in range(2_000):\n",
    "    # Forward\n",
    "    h = model(train_g, train_g.ndata[\"features\"])\n",
    "    pos_score = pred(train_pos_g, h, train_pos_g.edata[\"edge_features\"])\n",
    "    neg_score = pred(train_neg_g, h, train_neg_g.edata[\"edge_features\"])\n",
    "    loss = compute_loss(pos_score, neg_score)\n",
    "\n",
    "    # Backward\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if e % 5 == 0:\n",
    "        print('In epoch {}, loss: {}'.format(e, loss))\n",
    "\n",
    "\"\"\"# Evaluation\n",
    "with torch.no_grad():\n",
    "    h = model(test_g, test_g.ndata[\"features\"])\n",
    "    pos_score = pred(test_pos_g, h, test_pos_g.edata[\"edge_features\"])\n",
    "    neg_score = pred(test_neg_g, h, test_neg_g.edata[\"edge_features\"])\n",
    "    print('AUC', compute_auc(pos_score, neg_score))\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Sequential.forward() takes 2 positional arguments but 3 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m all_logits \u001b[39m=\u001b[39m []\n\u001b[1;32m      7\u001b[0m \u001b[39mfor\u001b[39;00m e \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m2_000\u001b[39m):\n\u001b[1;32m      8\u001b[0m     \u001b[39m# forward\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m     h \u001b[39m=\u001b[39m model(train_g, train_g\u001b[39m.\u001b[39;49mndata[\u001b[39m\"\u001b[39;49m\u001b[39mfeatures\u001b[39;49m\u001b[39m\"\u001b[39;49m])\n\u001b[1;32m     10\u001b[0m     pos_score \u001b[39m=\u001b[39m pred(train_pos_g, h, e)\n\u001b[1;32m     11\u001b[0m     neg_score \u001b[39m=\u001b[39m pred(train_neg_g, h, e)\n",
      "File \u001b[0;32m~/Documents/GitHub/BugPlusEngine/env/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[0;31mTypeError\u001b[0m: Sequential.forward() takes 2 positional arguments but 3 were given"
     ]
    }
   ],
   "source": [
    "# ----------- 3. set up loss and optimizer -------------- #\n",
    "# in this case, loss will in training loop\n",
    "optimizer = torch.optim.Adam(itertools.chain(model.parameters(), pred.parameters()), lr=0.01)\n",
    "\n",
    "# ----------- 4. training -------------------------------- #\n",
    "all_logits = []\n",
    "for e in range(2_000):\n",
    "    # forward\n",
    "    h = model(train_g, train_g.ndata[\"features\"])\n",
    "    pos_score = pred(train_pos_g, h, e)\n",
    "    neg_score = pred(train_neg_g, h, e)\n",
    "    loss = compute_loss(pos_score, neg_score)\n",
    "\n",
    "    # backward\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if e % 5 == 0:\n",
    "        print('In epoch {}, loss: {}'.format(e, loss))\n",
    "\n",
    "# ----------- 5. check results ------------------------ #\n",
    "from sklearn.metrics import roc_auc_score\n",
    "with torch.no_grad():\n",
    "    pos_score = pred(test_pos_g, h)\n",
    "    neg_score = pred(test_neg_g, h)\n",
    "    print('AUC', compute_auc(pos_score, neg_score))\n",
    "\n",
    "\n",
    "# Thumbnail credits: Link Prediction with Neo4j, Mark Needham\n",
    "# sphinx_gallery_thumbnail_path = '_static/blitz_4_link_predict.png'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 edges with highest scores:\n",
      "(0, 1): -364.8163\n",
      "(0, 1): -364.8163\n",
      "(1, 0): -364.8163\n",
      "(1, 0): -364.8163\n",
      "(1, 0): -364.8163\n",
      "(0, 2): -477.1709\n",
      "(0, 2): -477.1709\n",
      "(0, 2): -477.1709\n",
      "(2, 1): -1671.4236\n",
      "(2, 1): -1671.4236\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    test_g = train_g # graph to make predictions on\n",
    "    h = model(test_g, test_g.ndata['features']) # compute hidden representation of nodes in test graph\n",
    "    scores = pred(test_g, h) # make predictions using the scores function\n",
    "    scores = scores.detach().numpy() # convert scores to numpy array\n",
    "\n",
    "    # find the top 10 edges with highest scores\n",
    "    top10 = np.argsort(scores)[::-1][:10]\n",
    "    print('Top 10 edges with highest scores:')\n",
    "    for i in top10:\n",
    "        print('(%d, %d): %.4f' % (test_g.edges()[0][i], test_g.edges()[1][i], scores[i]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'features': tensor([[   0.,    2., -999., -999.,    3., -999.],\n",
       "        [-999., -999., -999., -999., -999., -999.],\n",
       "        [-999., -999., -999., -999., -999., -999.]])}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_graphs.ndata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Graph(num_nodes=3, num_edges=11,\n",
       "      ndata_schemes={'features': Scheme(shape=(6,), dtype=torch.float32)}\n",
       "      edata_schemes={'edge_features': Scheme(shape=(3,), dtype=torch.int64)})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Make a prediction on the first node pair.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m u, v \u001b[39m=\u001b[39m train_g\u001b[39m.\u001b[39medges()\n\u001b[0;32m----> 3\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mEdge features of the first edge:\u001b[39m\u001b[39m'\u001b[39m, train_g\u001b[39m.\u001b[39;49medata[\u001b[39m0\u001b[39;49m][\u001b[39m0\u001b[39m])\n\u001b[1;32m      4\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mPrediction score of the first edge:\u001b[39m\u001b[39m'\u001b[39m, pred(train_g, h)[\u001b[39m0\u001b[39m])\n",
      "File \u001b[0;32m~/Documents/GitHub/BugPlusEngine/env/lib/python3.10/site-packages/dgl/view.py:192\u001b[0m, in \u001b[0;36mHeteroEdgeDataView.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    190\u001b[0m     \u001b[39mreturn\u001b[39;00m ret\n\u001b[1;32m    191\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 192\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_graph\u001b[39m.\u001b[39;49m_get_e_repr(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_etid, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_edges)[key]\n",
      "File \u001b[0;32m~/Documents/GitHub/BugPlusEngine/env/lib/python3.10/site-packages/dgl/frame.py:622\u001b[0m, in \u001b[0;36mFrame.__getitem__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    609\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__getitem__\u001b[39m(\u001b[39mself\u001b[39m, name):\n\u001b[1;32m    610\u001b[0m     \u001b[39m\"\"\"Return the column of the given name.\u001b[39;00m\n\u001b[1;32m    611\u001b[0m \n\u001b[1;32m    612\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    620\u001b[0m \u001b[39m        Column data.\u001b[39;00m\n\u001b[1;32m    621\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 622\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_columns[name]\u001b[39m.\u001b[39mdata\n",
      "\u001b[0;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "# Make a prediction on the first node pair.\n",
    "u, v = train_g.edges()\n",
    "print('Edge features of the first edge:', train_g.edata[0])\n",
    "print('Prediction score of the first edge:', pred(train_g, h)[0])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store the graph and the deleted edge information in a list\n",
    "graphs = []\n",
    "target = []\n",
    "\n",
    "\n",
    "# Get all edges \n",
    "all_eids = all_graphs.edges()\n",
    "\n",
    "# Convert the tensor to a list for easier iteration\n",
    "all_eids = list(all_eids)\n",
    "\n",
    "# Loop through all edge ids\n",
    "for eid in range(len(all_eids[0])):\n",
    "    # Get the source and destination node id\n",
    "    u = all_eids[0][eid]\n",
    "    v = all_eids[1][eid]\n",
    "    # Append the edge to the deleted edges list\n",
    "    target.append((u, v, all_graphs.edges[u, v].data))\n",
    "    # Remove the edge from the graph\n",
    "    all_graphs = dgl.remove_edges(all_graphs, eid)                     \n",
    "    # Append the graph to the list\n",
    "    graphs.append(all_graphs)\n",
    "    # Add the edge back to the graph\n",
    "    all_graphs = dgl.add_edges(all_graphs, u, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(tensor(1),\n",
       "  tensor(0),\n",
       "  {'src_port': tensor([2]), 'dst_port': tensor([2]), 'edge_type': tensor([0])}),\n",
       " (tensor(1),\n",
       "  tensor(0),\n",
       "  {'src_port': tensor([4]), 'dst_port': tensor([4]), 'edge_type': tensor([1])}),\n",
       " (tensor(0),\n",
       "  tensor(2),\n",
       "  {'src_port': tensor([0]), 'dst_port': tensor([0]), 'edge_type': tensor([0])})]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target[:3]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dgl.nn import SAGEConv\n",
    "\n",
    "# ----------- 2. create model -------------- #\n",
    "# build a two-layer GraphSAGE model\n",
    "class GraphSAGE(nn.Module):\n",
    "    def __init__(self, in_feats, h_feats):\n",
    "        super(GraphSAGE, self).__init__()\n",
    "        self.conv1 = SAGEConv(in_feats, h_feats, 'mean')\n",
    "        self.conv2 = SAGEConv(h_feats, h_feats, 'mean')\n",
    "\n",
    "    def forward(self, g, in_feat):\n",
    "        h = self.conv1(g, in_feat)\n",
    "        h = F.relu(h)\n",
    "        h = self.conv2(g, h)\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the GCN message passing function\n",
    "class GCNLayer(nn.Module):\n",
    "    def __init__(self, in_feats, out_feats):\n",
    "        super(GCNLayer, self).__init__()\n",
    "        self.linear = nn.Linear(in_feats, out_feats)\n",
    "\n",
    "    def forward(self, g, inputs):\n",
    "        # Compute the node representations by message passing\n",
    "        g.ndata['h'] = inputs\n",
    "        g.update_all(fn.copy_src('h', 'm'), fn.sum('m', 'h'))\n",
    "        h = g.ndata.pop('h')\n",
    "        return self.linear(h)\n",
    "\n",
    "# Define the GCN model\n",
    "class GCN(nn.Module):\n",
    "    def __init__(self, in_feats, hidden_size, num_classes):\n",
    "        super(GCN, self).__init__()\n",
    "        self.gcn1 = GCNLayer(in_feats, hidden_size)\n",
    "        self.gcn2 = GCNLayer(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, g, inputs):\n",
    "        h = self.gcn1(g, inputs)\n",
    "        h = torch.relu(h)\n",
    "        h = self.gcn2(g, h)\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model, loss function, and optimizer\n",
    "model = GCN()\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Number of training epochs\n",
    "epochs = 100\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # Zero the gradients\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # Forward pass\n",
    "    outputs = model(features, adjacency_matrix)\n",
    "    \n",
    "    # Compute the loss\n",
    "    loss = criterion(outputs, labels)\n",
    "    \n",
    "    # Backward pass and optimization\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    # Print the loss every 10 epochs\n",
    "    if (epoch+1) % 10 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{epochs}], Loss: {loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and validation sets\n",
    "train_graphs = []\n",
    "train_deleted_edges = []\n",
    "val_graphs = []\n",
    "val_deleted_edges = []\n",
    "\n",
    "for graph, deleted_edge in zip(all_graphs, all_deleted_edges):\n",
    "    if random.random() < 0.8:\n",
    "        train_graphs.append(graph)\n",
    "        train_deleted_edges.append(deleted_edge)\n",
    "    else:\n",
    "        val_graphs.append(graph)\n",
    "        val_deleted_edges.append(deleted_edge)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not determine the shape of object type 'HeteroNodeDataView'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[61], line 37\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[39m# Define the adjacency matrices\u001b[39;00m\n\u001b[1;32m     36\u001b[0m adjacency_matrices \u001b[39m=\u001b[39m [torch\u001b[39m.\u001b[39mtensor(nx\u001b[39m.\u001b[39madjacency_matrix(g)\u001b[39m.\u001b[39mtodense()) \u001b[39mfor\u001b[39;00m g \u001b[39min\u001b[39;00m nx_graphs]\n\u001b[0;32m---> 37\u001b[0m node_features \u001b[39m=\u001b[39m [torch\u001b[39m.\u001b[39mtensor(g\u001b[39m.\u001b[39mndata) \u001b[39mfor\u001b[39;00m g \u001b[39min\u001b[39;00m graphs]\n\u001b[1;32m     40\u001b[0m \u001b[39m# Train the GCN model\u001b[39;00m\n\u001b[1;32m     41\u001b[0m model \u001b[39m=\u001b[39m GCN(in_features, hidden_features, out_features)\n",
      "Cell \u001b[0;32mIn[61], line 37\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[39m# Define the adjacency matrices\u001b[39;00m\n\u001b[1;32m     36\u001b[0m adjacency_matrices \u001b[39m=\u001b[39m [torch\u001b[39m.\u001b[39mtensor(nx\u001b[39m.\u001b[39madjacency_matrix(g)\u001b[39m.\u001b[39mtodense()) \u001b[39mfor\u001b[39;00m g \u001b[39min\u001b[39;00m nx_graphs]\n\u001b[0;32m---> 37\u001b[0m node_features \u001b[39m=\u001b[39m [torch\u001b[39m.\u001b[39;49mtensor(g\u001b[39m.\u001b[39;49mndata) \u001b[39mfor\u001b[39;00m g \u001b[39min\u001b[39;00m graphs]\n\u001b[1;32m     40\u001b[0m \u001b[39m# Train the GCN model\u001b[39;00m\n\u001b[1;32m     41\u001b[0m model \u001b[39m=\u001b[39m GCN(in_features, hidden_features, out_features)\n",
      "\u001b[0;31mValueError\u001b[0m: could not determine the shape of object type 'HeteroNodeDataView'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Define your GCN model\n",
    "class GCN(nn.Module):\n",
    "    def __init__(self, in_features, hidden_features, out_features):\n",
    "        super(GCN, self).__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(in_features, hidden_features),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_features, out_features)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x, adj):\n",
    "        x = self.layers(x)\n",
    "        x = torch.mm(adj, x)\n",
    "        return x\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# in_features is the number of features of each node\n",
    "in_features = graphs[0].number_of_nodes()\n",
    "# hidden_features is the number of features of the hidden layer\n",
    "hidden_features = 16\n",
    "# out_features is the number of features of the output\n",
    "out_features = 1\n",
    "\n",
    "# Define the adjacency matrices\n",
    "# Convert the DGL heterographs to NetworkX graphs\n",
    "nx_graphs = [g.to_networkx() for g in graphs]\n",
    "\n",
    "# Define the adjacency matrices\n",
    "adjacency_matrices = [torch.tensor(nx.adjacency_matrix(g).todense()) for g in nx_graphs]\n",
    "node_features = [torch.tensor(g.ndata) for g in graphs]\n",
    "\n",
    "\n",
    "# Train the GCN model\n",
    "model = GCN(in_features, hidden_features, out_features)\n",
    "model.train()\n",
    "num_epochs = 100\n",
    "for epoch in range(num_epochs):\n",
    "    # Zero the gradients\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # Forward pass\n",
    "    outputs = [model(g, adj) for g, adj in zip(graphs, adjacency_matrices)]\n",
    "    outputs = torch.cat(outputs, dim=0)\n",
    "    loss = criterion(outputs, target)\n",
    "    \n",
    "    # Backward pass\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    # Print the loss every 10 epochs\n",
    "    if epoch % 10 == 0:\n",
    "        print(f'Epoch {epoch}, Loss: {loss.item()}')\n",
    "\n",
    "# Evaluation\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    outputs = [model(g, adj) for g, adj in zip(graphs, adjacency_matrices)]\n",
    "    outputs = torch.cat(outputs, dim=0)\n",
    "    loss = criterion(outputs, target)\n",
    "    print(f'Final loss: {loss.item()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11 11\n"
     ]
    }
   ],
   "source": [
    "print(len(train_graphs), len(train_deleted_edges))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "070cdce012dd41a01f1f0ff20239b474e092c7a2b169ddafdace8d691490e16c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
