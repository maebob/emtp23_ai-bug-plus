{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data from the pickle file\n",
    "with open('../../training_set.pkl', 'rb') as f:\n",
    "    train_data = pickle.load(f)\n",
    "\n",
    "with open('../../test_set.pkl', 'rb') as f:\n",
    "    test_data = pickle.load(f)\n",
    "\n",
    "\n",
    "# Convert the data to a NumPy array \n",
    "train_data = np.array(train_data)\n",
    "test_data = np.array(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17568, 74)\n"
     ]
    }
   ],
   "source": [
    "# Look at the data\n",
    "print(train_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12. 11. 13.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0. 65.]\n"
     ]
    }
   ],
   "source": [
    "print(train_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17568, 73)\n"
     ]
    }
   ],
   "source": [
    "# Split the data into input and output\n",
    "# every row is a config\n",
    "# every column is a value\n",
    "# the last column is the output\n",
    "# the first 3 columns are the input\n",
    "# The first vlaue is the up value\n",
    "# The second value is the down value\n",
    "# The third value is the output value\n",
    "\n",
    "x_train = train_data[:, :-1]\n",
    "y_train = train_data[:, -1]\n",
    "x_test = test_data[:, :-1]\n",
    "y_test = test_data[:, -1]\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[12. 11. 13.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.]]\n"
     ]
    }
   ],
   "source": [
    "# Look at first row of input\n",
    "print(x_train[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[65.]\n"
     ]
    }
   ],
   "source": [
    "# Look at first row of output\n",
    "print(y_train[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Layer\n",
    "import keras.backend as K\n",
    "\n",
    "class Round(Layer):\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        super(Round, self).__init__(**kwargs)\n",
    "\n",
    "    def get_output(self, train=True):\n",
    "        X = self.get_input(train)\n",
    "        return K.round(X)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {\"name\": self.__class__.__name__}\n",
    "        base_config = super(Round, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build basic model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1\n",
      "\n",
      "systemMemory: 16.00 GB\n",
      "maxCacheSize: 5.33 GB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-02 13:34:35.879112: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-01-02 13:34:35.879618: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "# Build the model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(73, activation='relu', input_shape=(x_train.shape[1],), name='input'),\n",
    "    tf.keras.layers.Dense(64, activation='relu', name='hidden'),\n",
    "    tf.keras.layers.Dense(10, activation='softmax', name='output'),\n",
    "    # add a layer that rounds the output to the nearest integer\n",
    "    #tf.keras.layers.Lambda(lambda x: tf.round(x))\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First define baseline model. Then use it in Keras Classifier for the training\n",
    "def baseline_model():\n",
    "    # Create model here\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.Dense(73, input_dim =73, activation = 'relu')) # Rectified Linear Unit Activation Function\n",
    "    model.add(tf.keras.layers.Dense(15, activation = 'relu'))\n",
    "    model.add(tf.keras.layers.Dense(34, activation = 'softmax')) # Softmax for multi-class classification\n",
    "    # Compile model here\n",
    "    model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['categorical_accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0q/8f0zskws27x_14w3qmfndjfw0000gn/T/ipykernel_27353/369795368.py:2: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  estimator = tf.keras.wrappers.scikit_learn.KerasClassifier(build_fn = baseline_model, epochs = 100, batch_size = 64, verbose = 1)\n"
     ]
    }
   ],
   "source": [
    "# Create Keras Classifier and use predefined baseline model\n",
    "estimator = tf.keras.wrappers.scikit_learn.KerasClassifier(build_fn = baseline_model, epochs = 100, batch_size = 64, verbose = 1)\n",
    "# Try different values for epoch and batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-02 13:34:36.255003: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120\n",
      "  1/275 [..............................] - ETA: 1:55 - loss: 4.0839 - categorical_accuracy: 0.0156"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-02 13:34:36.520208: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "275/275 [==============================] - 4s 13ms/step - loss: 2.8638 - categorical_accuracy: 0.1878\n",
      "Epoch 2/120\n",
      "275/275 [==============================] - 3s 10ms/step - loss: 1.4455 - categorical_accuracy: 0.6404\n",
      "Epoch 3/120\n",
      "275/275 [==============================] - 3s 10ms/step - loss: 0.6552 - categorical_accuracy: 0.8608\n",
      "Epoch 4/120\n",
      "275/275 [==============================] - 3s 10ms/step - loss: 0.3435 - categorical_accuracy: 0.8961\n",
      "Epoch 5/120\n",
      "275/275 [==============================] - 3s 10ms/step - loss: 0.2494 - categorical_accuracy: 0.9025\n",
      "Epoch 6/120\n",
      "275/275 [==============================] - 3s 10ms/step - loss: 0.2167 - categorical_accuracy: 0.9009\n",
      "Epoch 7/120\n",
      "275/275 [==============================] - 3s 9ms/step - loss: 0.2022 - categorical_accuracy: 0.9045\n",
      "Epoch 8/120\n",
      "275/275 [==============================] - 3s 10ms/step - loss: 0.1961 - categorical_accuracy: 0.9014\n",
      "Epoch 9/120\n",
      "275/275 [==============================] - 3s 10ms/step - loss: 0.1921 - categorical_accuracy: 0.9064\n",
      "Epoch 10/120\n",
      "275/275 [==============================] - 3s 10ms/step - loss: 0.1905 - categorical_accuracy: 0.9025\n",
      "Epoch 11/120\n",
      "275/275 [==============================] - 3s 10ms/step - loss: 0.1900 - categorical_accuracy: 0.9043\n",
      "Epoch 12/120\n",
      "275/275 [==============================] - 3s 10ms/step - loss: 0.1863 - categorical_accuracy: 0.9055\n",
      "Epoch 13/120\n",
      "275/275 [==============================] - 3s 10ms/step - loss: 0.1850 - categorical_accuracy: 0.9057\n",
      "Epoch 14/120\n",
      "275/275 [==============================] - 3s 9ms/step - loss: 0.1843 - categorical_accuracy: 0.9058\n",
      "Epoch 15/120\n",
      "275/275 [==============================] - 3s 10ms/step - loss: 0.1820 - categorical_accuracy: 0.9078\n",
      "Epoch 16/120\n",
      "275/275 [==============================] - 3s 10ms/step - loss: 0.1810 - categorical_accuracy: 0.9062\n",
      "Epoch 17/120\n",
      "275/275 [==============================] - 3s 10ms/step - loss: 0.1814 - categorical_accuracy: 0.9077\n",
      "Epoch 18/120\n",
      "275/275 [==============================] - 3s 9ms/step - loss: 0.1788 - categorical_accuracy: 0.9099\n",
      "Epoch 19/120\n",
      "275/275 [==============================] - 3s 10ms/step - loss: 0.1795 - categorical_accuracy: 0.9068\n",
      "Epoch 20/120\n",
      "275/275 [==============================] - 3s 9ms/step - loss: 0.1792 - categorical_accuracy: 0.9077\n",
      "Epoch 21/120\n",
      "275/275 [==============================] - 3s 9ms/step - loss: 0.1788 - categorical_accuracy: 0.9072\n",
      "Epoch 22/120\n",
      "275/275 [==============================] - 3s 9ms/step - loss: 0.1782 - categorical_accuracy: 0.9097\n",
      "Epoch 23/120\n",
      "275/275 [==============================] - 3s 10ms/step - loss: 0.1766 - categorical_accuracy: 0.9073\n",
      "Epoch 24/120\n",
      "275/275 [==============================] - 3s 9ms/step - loss: 0.1766 - categorical_accuracy: 0.9072\n",
      "Epoch 25/120\n",
      "275/275 [==============================] - 3s 10ms/step - loss: 0.1778 - categorical_accuracy: 0.9077\n",
      "Epoch 26/120\n",
      "275/275 [==============================] - 3s 9ms/step - loss: 0.1758 - categorical_accuracy: 0.9084\n",
      "Epoch 27/120\n",
      "275/275 [==============================] - 3s 9ms/step - loss: 0.1757 - categorical_accuracy: 0.9081\n",
      "Epoch 28/120\n",
      "275/275 [==============================] - 3s 9ms/step - loss: 0.1754 - categorical_accuracy: 0.9088\n",
      "Epoch 29/120\n",
      "275/275 [==============================] - 3s 10ms/step - loss: 0.1757 - categorical_accuracy: 0.9095\n",
      "Epoch 30/120\n",
      "275/275 [==============================] - 3s 9ms/step - loss: 0.1744 - categorical_accuracy: 0.9086\n",
      "Epoch 31/120\n",
      "275/275 [==============================] - 3s 9ms/step - loss: 0.1754 - categorical_accuracy: 0.9070\n",
      "Epoch 32/120\n",
      "275/275 [==============================] - 3s 9ms/step - loss: 0.1735 - categorical_accuracy: 0.9106\n",
      "Epoch 33/120\n",
      "275/275 [==============================] - 3s 9ms/step - loss: 0.1750 - categorical_accuracy: 0.9076\n",
      "Epoch 34/120\n",
      "275/275 [==============================] - 3s 9ms/step - loss: 0.1743 - categorical_accuracy: 0.9089\n",
      "Epoch 35/120\n",
      "275/275 [==============================] - 3s 10ms/step - loss: 0.1742 - categorical_accuracy: 0.9090\n",
      "Epoch 36/120\n",
      "275/275 [==============================] - 3s 9ms/step - loss: 0.1732 - categorical_accuracy: 0.9080\n",
      "Epoch 37/120\n",
      "275/275 [==============================] - 3s 9ms/step - loss: 0.1740 - categorical_accuracy: 0.9084\n",
      "Epoch 38/120\n",
      "275/275 [==============================] - 3s 10ms/step - loss: 0.1740 - categorical_accuracy: 0.9090\n",
      "Epoch 39/120\n",
      "275/275 [==============================] - 3s 9ms/step - loss: 0.1725 - categorical_accuracy: 0.9081\n",
      "Epoch 40/120\n",
      "275/275 [==============================] - 3s 10ms/step - loss: 0.1730 - categorical_accuracy: 0.9096\n",
      "Epoch 41/120\n",
      "275/275 [==============================] - 3s 10ms/step - loss: 0.1723 - categorical_accuracy: 0.9096\n",
      "Epoch 42/120\n",
      "275/275 [==============================] - 3s 9ms/step - loss: 0.1726 - categorical_accuracy: 0.9085\n",
      "Epoch 43/120\n",
      "275/275 [==============================] - 3s 9ms/step - loss: 0.1731 - categorical_accuracy: 0.9089\n",
      "Epoch 44/120\n",
      "275/275 [==============================] - 3s 9ms/step - loss: 0.1720 - categorical_accuracy: 0.9099\n",
      "Epoch 45/120\n",
      "275/275 [==============================] - 3s 9ms/step - loss: 0.1725 - categorical_accuracy: 0.9112\n",
      "Epoch 46/120\n",
      "275/275 [==============================] - 3s 10ms/step - loss: 0.1719 - categorical_accuracy: 0.9109\n",
      "Epoch 47/120\n",
      "275/275 [==============================] - 3s 9ms/step - loss: 0.1722 - categorical_accuracy: 0.9121\n",
      "Epoch 48/120\n",
      "275/275 [==============================] - 3s 9ms/step - loss: 0.1725 - categorical_accuracy: 0.9077\n",
      "Epoch 49/120\n",
      "275/275 [==============================] - 3s 9ms/step - loss: 0.1726 - categorical_accuracy: 0.9081\n",
      "Epoch 50/120\n",
      "275/275 [==============================] - 3s 9ms/step - loss: 0.1720 - categorical_accuracy: 0.9060\n",
      "Epoch 51/120\n",
      "275/275 [==============================] - 3s 9ms/step - loss: 0.1718 - categorical_accuracy: 0.9090\n",
      "Epoch 52/120\n",
      "275/275 [==============================] - 3s 9ms/step - loss: 0.1723 - categorical_accuracy: 0.9057\n",
      "Epoch 53/120\n",
      "275/275 [==============================] - 3s 10ms/step - loss: 0.1721 - categorical_accuracy: 0.9092\n",
      "Epoch 54/120\n",
      "275/275 [==============================] - 3s 9ms/step - loss: 0.1715 - categorical_accuracy: 0.9101\n",
      "Epoch 55/120\n",
      "275/275 [==============================] - 3s 10ms/step - loss: 0.1718 - categorical_accuracy: 0.9087\n",
      "Epoch 56/120\n",
      "275/275 [==============================] - 3s 9ms/step - loss: 0.1713 - categorical_accuracy: 0.9076\n",
      "Epoch 57/120\n",
      "275/275 [==============================] - 3s 9ms/step - loss: 0.1711 - categorical_accuracy: 0.9121\n",
      "Epoch 58/120\n",
      "275/275 [==============================] - 3s 10ms/step - loss: 0.1705 - categorical_accuracy: 0.9104\n",
      "Epoch 59/120\n",
      "275/275 [==============================] - 3s 9ms/step - loss: 0.1704 - categorical_accuracy: 0.9090\n",
      "Epoch 60/120\n",
      "275/275 [==============================] - 3s 9ms/step - loss: 0.1706 - categorical_accuracy: 0.9111\n",
      "Epoch 61/120\n",
      "275/275 [==============================] - 3s 10ms/step - loss: 0.1709 - categorical_accuracy: 0.9092\n",
      "Epoch 62/120\n",
      "275/275 [==============================] - 3s 10ms/step - loss: 0.1706 - categorical_accuracy: 0.9106\n",
      "Epoch 63/120\n",
      "275/275 [==============================] - 3s 10ms/step - loss: 0.1704 - categorical_accuracy: 0.9112\n",
      "Epoch 64/120\n",
      "275/275 [==============================] - 3s 10ms/step - loss: 0.1704 - categorical_accuracy: 0.9087\n",
      "Epoch 65/120\n",
      "275/275 [==============================] - 3s 9ms/step - loss: 0.1704 - categorical_accuracy: 0.9085\n",
      "Epoch 66/120\n",
      "275/275 [==============================] - 3s 10ms/step - loss: 0.1708 - categorical_accuracy: 0.9099\n",
      "Epoch 67/120\n",
      "275/275 [==============================] - 3s 9ms/step - loss: 0.1707 - categorical_accuracy: 0.9102\n",
      "Epoch 68/120\n",
      "275/275 [==============================] - 3s 10ms/step - loss: 0.1702 - categorical_accuracy: 0.9104\n",
      "Epoch 69/120\n",
      "275/275 [==============================] - 3s 10ms/step - loss: 0.1703 - categorical_accuracy: 0.9089\n",
      "Epoch 70/120\n",
      "275/275 [==============================] - 3s 9ms/step - loss: 0.1701 - categorical_accuracy: 0.9097\n",
      "Epoch 71/120\n",
      "275/275 [==============================] - 3s 9ms/step - loss: 0.1703 - categorical_accuracy: 0.9100\n",
      "Epoch 72/120\n",
      "275/275 [==============================] - 3s 10ms/step - loss: 0.1703 - categorical_accuracy: 0.9091\n",
      "Epoch 73/120\n",
      "275/275 [==============================] - 3s 10ms/step - loss: 0.1701 - categorical_accuracy: 0.9083\n",
      "Epoch 74/120\n",
      "275/275 [==============================] - 3s 10ms/step - loss: 0.1699 - categorical_accuracy: 0.9094\n",
      "Epoch 75/120\n",
      "275/275 [==============================] - 3s 10ms/step - loss: 0.1704 - categorical_accuracy: 0.9119\n",
      "Epoch 76/120\n",
      "275/275 [==============================] - 3s 9ms/step - loss: 0.1704 - categorical_accuracy: 0.9087\n",
      "Epoch 77/120\n",
      "275/275 [==============================] - 3s 10ms/step - loss: 0.1702 - categorical_accuracy: 0.9087\n",
      "Epoch 78/120\n",
      "275/275 [==============================] - 3s 10ms/step - loss: 0.1703 - categorical_accuracy: 0.9099\n",
      "Epoch 79/120\n",
      "275/275 [==============================] - 3s 10ms/step - loss: 0.1699 - categorical_accuracy: 0.9090\n",
      "Epoch 80/120\n",
      "275/275 [==============================] - 3s 10ms/step - loss: 0.1698 - categorical_accuracy: 0.9081\n",
      "Epoch 81/120\n",
      "275/275 [==============================] - 3s 10ms/step - loss: 0.1701 - categorical_accuracy: 0.9097\n",
      "Epoch 82/120\n",
      "275/275 [==============================] - 3s 10ms/step - loss: 0.1694 - categorical_accuracy: 0.9096\n",
      "Epoch 83/120\n",
      "275/275 [==============================] - 3s 10ms/step - loss: 0.1699 - categorical_accuracy: 0.9081\n",
      "Epoch 84/120\n",
      "275/275 [==============================] - 3s 10ms/step - loss: 0.1701 - categorical_accuracy: 0.9110\n",
      "Epoch 85/120\n",
      "275/275 [==============================] - 3s 10ms/step - loss: 0.1700 - categorical_accuracy: 0.9093\n",
      "Epoch 86/120\n",
      "275/275 [==============================] - 3s 11ms/step - loss: 0.1696 - categorical_accuracy: 0.9103\n",
      "Epoch 87/120\n",
      "275/275 [==============================] - 3s 10ms/step - loss: 0.1697 - categorical_accuracy: 0.9076\n",
      "Epoch 88/120\n",
      "275/275 [==============================] - 3s 10ms/step - loss: 0.1696 - categorical_accuracy: 0.9097\n",
      "Epoch 89/120\n",
      "275/275 [==============================] - 3s 10ms/step - loss: 0.1696 - categorical_accuracy: 0.9095\n",
      "Epoch 90/120\n",
      "275/275 [==============================] - 3s 10ms/step - loss: 0.1719 - categorical_accuracy: 0.9098\n",
      "Epoch 91/120\n",
      "275/275 [==============================] - 3s 10ms/step - loss: 0.1696 - categorical_accuracy: 0.9090\n",
      "Epoch 92/120\n",
      "275/275 [==============================] - 3s 10ms/step - loss: 0.1695 - categorical_accuracy: 0.9102\n",
      "Epoch 93/120\n",
      "275/275 [==============================] - 3s 10ms/step - loss: 0.1696 - categorical_accuracy: 0.9078\n",
      "Epoch 94/120\n",
      "275/275 [==============================] - 3s 10ms/step - loss: 0.1696 - categorical_accuracy: 0.9111\n",
      "Epoch 95/120\n",
      "275/275 [==============================] - 3s 10ms/step - loss: 0.1694 - categorical_accuracy: 0.9101\n",
      "Epoch 96/120\n",
      "275/275 [==============================] - 3s 10ms/step - loss: 0.1701 - categorical_accuracy: 0.9072\n",
      "Epoch 97/120\n",
      "275/275 [==============================] - 3s 10ms/step - loss: 0.1695 - categorical_accuracy: 0.9094\n",
      "Epoch 98/120\n",
      "275/275 [==============================] - 3s 10ms/step - loss: 0.1696 - categorical_accuracy: 0.9084\n",
      "Epoch 99/120\n",
      "275/275 [==============================] - 3s 10ms/step - loss: 0.1694 - categorical_accuracy: 0.9099\n",
      "Epoch 100/120\n",
      "275/275 [==============================] - 3s 10ms/step - loss: 0.1696 - categorical_accuracy: 0.9086\n",
      "Epoch 101/120\n",
      "275/275 [==============================] - 3s 10ms/step - loss: 0.1695 - categorical_accuracy: 0.9094\n",
      "Epoch 102/120\n",
      "275/275 [==============================] - 3s 10ms/step - loss: 0.1696 - categorical_accuracy: 0.9094\n",
      "Epoch 103/120\n",
      "275/275 [==============================] - 3s 10ms/step - loss: 0.1702 - categorical_accuracy: 0.9101\n",
      "Epoch 104/120\n",
      "275/275 [==============================] - 3s 10ms/step - loss: 0.1695 - categorical_accuracy: 0.9101\n",
      "Epoch 105/120\n",
      "275/275 [==============================] - 3s 10ms/step - loss: 0.1710 - categorical_accuracy: 0.9102\n",
      "Epoch 106/120\n",
      "275/275 [==============================] - 3s 9ms/step - loss: 0.1694 - categorical_accuracy: 0.9098\n",
      "Epoch 107/120\n",
      "275/275 [==============================] - 3s 9ms/step - loss: 0.1693 - categorical_accuracy: 0.9102\n",
      "Epoch 108/120\n",
      "275/275 [==============================] - 3s 9ms/step - loss: 0.1694 - categorical_accuracy: 0.9095\n",
      "Epoch 109/120\n",
      "275/275 [==============================] - 3s 9ms/step - loss: 0.1694 - categorical_accuracy: 0.9101\n",
      "Epoch 110/120\n",
      "275/275 [==============================] - 3s 10ms/step - loss: 0.1696 - categorical_accuracy: 0.9088\n",
      "Epoch 111/120\n",
      "275/275 [==============================] - 3s 10ms/step - loss: 0.1690 - categorical_accuracy: 0.9123\n",
      "Epoch 112/120\n",
      "275/275 [==============================] - 3s 10ms/step - loss: 0.1696 - categorical_accuracy: 0.9080\n",
      "Epoch 113/120\n",
      "275/275 [==============================] - 3s 9ms/step - loss: 0.1692 - categorical_accuracy: 0.9096\n",
      "Epoch 114/120\n",
      "275/275 [==============================] - 3s 10ms/step - loss: 0.1696 - categorical_accuracy: 0.9068\n",
      "Epoch 115/120\n",
      "275/275 [==============================] - 3s 9ms/step - loss: 0.1695 - categorical_accuracy: 0.9098\n",
      "Epoch 116/120\n",
      "275/275 [==============================] - 3s 10ms/step - loss: 0.1695 - categorical_accuracy: 0.9094\n",
      "Epoch 117/120\n",
      "275/275 [==============================] - 3s 9ms/step - loss: 0.1697 - categorical_accuracy: 0.9089\n",
      "Epoch 118/120\n",
      "275/275 [==============================] - 3s 9ms/step - loss: 0.1693 - categorical_accuracy: 0.9090\n",
      "Epoch 119/120\n",
      "275/275 [==============================] - 3s 10ms/step - loss: 0.1695 - categorical_accuracy: 0.9094\n",
      "Epoch 120/120\n",
      "275/275 [==============================] - 3s 10ms/step - loss: 0.1695 - categorical_accuracy: 0.9100\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x14fc07910>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "estimator.fit(x_train, y_train, epochs=120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'KerasClassifier' object has no attribute 'save'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Save the estimator\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m estimator\u001b[39m.\u001b[39;49msave(\u001b[39m'\u001b[39m\u001b[39mestimator.h5\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'KerasClassifier' object has no attribute 'save'"
     ]
    }
   ],
   "source": [
    "# Save the estimator\n",
    "#estimator.save('estimator.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 6/69 [=>............................] - ETA: 0s - loss: 0.1682 - categorical_accuracy: 0.9167 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-02 13:40:13.806237: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69/69 [==============================] - 1s 9ms/step - loss: 0.1816 - categorical_accuracy: 0.8985\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The model is not configured to compute accuracy. You should pass `metrics=[\"accuracy\"]` to the `model.compile()` method.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Evaluate the estimator\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m estimator\u001b[39m.\u001b[39;49mscore(x_test, y_test)\n",
      "File \u001b[0;32m~/Documents/GitHub/BugPlusEngine/env/lib/python3.10/site-packages/keras/wrappers/scikit_learn.py:323\u001b[0m, in \u001b[0;36mKerasClassifier.score\u001b[0;34m(self, x, y, **kwargs)\u001b[0m\n\u001b[1;32m    321\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39min\u001b[39;00m [\u001b[39m'\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39macc\u001b[39m\u001b[39m'\u001b[39m]:\n\u001b[1;32m    322\u001b[0m     \u001b[39mreturn\u001b[39;00m output\n\u001b[0;32m--> 323\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mThe model is not configured to compute accuracy. \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    324\u001b[0m                  \u001b[39m'\u001b[39m\u001b[39mYou should pass `metrics=[\u001b[39m\u001b[39m\"\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m]` to \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    325\u001b[0m                  \u001b[39m'\u001b[39m\u001b[39mthe `model.compile()` method.\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: The model is not configured to compute accuracy. You should pass `metrics=[\"accuracy\"]` to the `model.compile()` method."
     ]
    }
   ],
   "source": [
    "# Evaluate the estimator\n",
    "#estimator.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 70/138 [==============>...............] - ETA: 0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-02 13:41:05.384171: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "138/138 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions = estimator.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "138/138 [==============================] - 0s 3ms/step\n",
      "66.0 65.0\n",
      "68.0 66.0\n",
      "65.0 66.0\n",
      "65.0 66.0\n",
      "68.0 58.0\n",
      "68.0 66.0\n",
      "68.0 66.0\n",
      "68.0 58.0\n",
      "68.0 66.0\n",
      "66.0 65.0\n",
      "68.0 65.0\n",
      "65.0 66.0\n",
      "68.0 66.0\n",
      "66.0 58.0\n",
      "65.0 66.0\n",
      "66.0 65.0\n",
      "68.0 66.0\n",
      "65.0 66.0\n",
      "66.0 68.0\n",
      "66.0 68.0\n",
      "68.0 58.0\n",
      "66.0 68.0\n",
      "66.0 68.0\n",
      "66.0 68.0\n",
      "66.0 68.0\n",
      "68.0 65.0\n",
      "66.0 58.0\n",
      "68.0 66.0\n",
      "68.0 65.0\n",
      "68.0 66.0\n",
      "66.0 58.0\n",
      "66.0 65.0\n",
      "66.0 68.0\n",
      "65.0 66.0\n",
      "68.0 58.0\n",
      "66.0 65.0\n",
      "66.0 68.0\n",
      "65.0 66.0\n",
      "0.0 1.0\n",
      "66.0 58.0\n",
      "68.0 65.0\n",
      "66.0 68.0\n",
      "66.0 58.0\n",
      "66.0 58.0\n",
      "66.0 68.0\n",
      "68.0 66.0\n",
      "66.0 68.0\n",
      "65.0 66.0\n",
      "66.0 68.0\n",
      "68.0 66.0\n",
      "68.0 65.0\n",
      "66.0 68.0\n",
      "66.0 65.0\n",
      "66.0 68.0\n",
      "66.0 68.0\n",
      "66.0 65.0\n",
      "65.0 66.0\n",
      "66.0 68.0\n",
      "66.0 68.0\n",
      "66.0 68.0\n",
      "66.0 68.0\n",
      "66.0 68.0\n",
      "68.0 65.0\n",
      "66.0 58.0\n",
      "66.0 68.0\n",
      "65.0 66.0\n",
      "66.0 65.0\n",
      "66.0 68.0\n",
      "66.0 68.0\n",
      "66.0 68.0\n",
      "65.0 66.0\n",
      "66.0 65.0\n",
      "66.0 58.0\n",
      "68.0 66.0\n",
      "66.0 68.0\n",
      "66.0 68.0\n",
      "65.0 66.0\n",
      "66.0 68.0\n",
      "66.0 68.0\n",
      "66.0 68.0\n",
      "66.0 58.0\n",
      "68.0 66.0\n",
      "66.0 58.0\n",
      "65.0 66.0\n",
      "68.0 66.0\n",
      "68.0 65.0\n",
      "68.0 58.0\n",
      "66.0 68.0\n",
      "68.0 58.0\n",
      "65.0 66.0\n",
      "66.0 58.0\n",
      "68.0 66.0\n",
      "66.0 68.0\n",
      "68.0 66.0\n",
      "65.0 66.0\n",
      "66.0 58.0\n",
      "66.0 58.0\n",
      "65.0 66.0\n",
      "66.0 68.0\n",
      "65.0 66.0\n",
      "66.0 68.0\n",
      "66.0 65.0\n",
      "68.0 66.0\n",
      "66.0 68.0\n",
      "66.0 65.0\n",
      "66.0 58.0\n",
      "65.0 66.0\n",
      "66.0 68.0\n",
      "66.0 68.0\n",
      "66.0 58.0\n",
      "68.0 66.0\n",
      "65.0 66.0\n",
      "65.0 66.0\n",
      "66.0 65.0\n",
      "66.0 58.0\n",
      "66.0 65.0\n",
      "68.0 58.0\n",
      "65.0 66.0\n",
      "65.0 66.0\n",
      "66.0 65.0\n",
      "68.0 66.0\n",
      "66.0 68.0\n",
      "65.0 66.0\n",
      "66.0 65.0\n",
      "68.0 66.0\n",
      "66.0 68.0\n",
      "68.0 66.0\n",
      "66.0 65.0\n",
      "65.0 66.0\n",
      "66.0 68.0\n",
      "66.0 68.0\n",
      "66.0 65.0\n",
      "68.0 66.0\n",
      "66.0 68.0\n",
      "66.0 68.0\n",
      "68.0 65.0\n",
      "66.0 68.0\n",
      "68.0 58.0\n",
      "65.0 66.0\n",
      "65.0 66.0\n",
      "68.0 65.0\n",
      "66.0 68.0\n",
      "66.0 58.0\n",
      "68.0 58.0\n",
      "65.0 66.0\n",
      "66.0 65.0\n",
      "66.0 65.0\n",
      "66.0 68.0\n",
      "66.0 58.0\n",
      "65.0 66.0\n",
      "66.0 58.0\n",
      "66.0 68.0\n",
      "66.0 65.0\n",
      "68.0 65.0\n",
      "65.0 66.0\n",
      "65.0 66.0\n",
      "68.0 66.0\n",
      "66.0 68.0\n",
      "68.0 58.0\n",
      "66.0 58.0\n",
      "68.0 65.0\n",
      "66.0 58.0\n",
      "66.0 68.0\n",
      "68.0 58.0\n",
      "66.0 68.0\n",
      "68.0 65.0\n",
      "68.0 65.0\n",
      "66.0 68.0\n",
      "66.0 58.0\n",
      "66.0 68.0\n",
      "65.0 66.0\n",
      "68.0 66.0\n",
      "66.0 65.0\n",
      "68.0 58.0\n",
      "65.0 66.0\n",
      "68.0 66.0\n",
      "66.0 68.0\n",
      "68.0 58.0\n",
      "65.0 66.0\n",
      "66.0 68.0\n",
      "68.0 66.0\n",
      "68.0 66.0\n",
      "68.0 65.0\n",
      "66.0 58.0\n",
      "68.0 65.0\n",
      "66.0 68.0\n",
      "68.0 65.0\n",
      "66.0 65.0\n",
      "66.0 65.0\n",
      "65.0 66.0\n",
      "68.0 66.0\n",
      "66.0 58.0\n",
      "66.0 68.0\n",
      "66.0 68.0\n",
      "68.0 66.0\n",
      "66.0 58.0\n",
      "65.0 66.0\n",
      "66.0 58.0\n",
      "66.0 68.0\n",
      "68.0 66.0\n",
      "68.0 66.0\n",
      "65.0 66.0\n",
      "66.0 58.0\n",
      "68.0 66.0\n",
      "68.0 66.0\n",
      "66.0 65.0\n",
      "66.0 68.0\n",
      "66.0 68.0\n",
      "66.0 68.0\n",
      "68.0 58.0\n",
      "66.0 65.0\n",
      "65.0 66.0\n",
      "66.0 68.0\n",
      "66.0 65.0\n",
      "66.0 68.0\n",
      "66.0 65.0\n",
      "66.0 68.0\n",
      "68.0 66.0\n",
      "66.0 58.0\n",
      "68.0 65.0\n",
      "66.0 68.0\n",
      "68.0 58.0\n",
      "65.0 66.0\n",
      "66.0 68.0\n",
      "68.0 66.0\n",
      "65.0 66.0\n",
      "66.0 68.0\n",
      "68.0 66.0\n",
      "65.0 66.0\n",
      "66.0 68.0\n",
      "66.0 58.0\n",
      "66.0 68.0\n",
      "66.0 68.0\n",
      "66.0 65.0\n",
      "65.0 66.0\n",
      "66.0 68.0\n",
      "68.0 66.0\n",
      "66.0 65.0\n",
      "66.0 68.0\n",
      "68.0 58.0\n",
      "65.0 66.0\n",
      "68.0 58.0\n",
      "68.0 66.0\n",
      "65.0 66.0\n",
      "66.0 68.0\n",
      "68.0 66.0\n",
      "68.0 65.0\n",
      "68.0 66.0\n",
      "68.0 66.0\n",
      "65.0 66.0\n",
      "65.0 66.0\n",
      "68.0 66.0\n",
      "68.0 66.0\n",
      "66.0 58.0\n",
      "66.0 65.0\n",
      "65.0 66.0\n",
      "65.0 66.0\n",
      "68.0 58.0\n",
      "68.0 58.0\n",
      "68.0 66.0\n",
      "65.0 66.0\n",
      "65.0 66.0\n",
      "66.0 58.0\n",
      "66.0 65.0\n",
      "66.0 68.0\n",
      "68.0 66.0\n",
      "66.0 65.0\n",
      "66.0 65.0\n",
      "66.0 65.0\n",
      "66.0 68.0\n",
      "66.0 68.0\n",
      "66.0 65.0\n",
      "68.0 66.0\n",
      "66.0 65.0\n",
      "66.0 58.0\n",
      "68.0 65.0\n",
      "66.0 65.0\n",
      "68.0 58.0\n",
      "66.0 68.0\n",
      "66.0 58.0\n",
      "66.0 58.0\n",
      "68.0 66.0\n",
      "66.0 68.0\n",
      "66.0 58.0\n",
      "66.0 68.0\n",
      "65.0 66.0\n",
      "68.0 66.0\n",
      "68.0 66.0\n",
      "68.0 66.0\n",
      "68.0 65.0\n",
      "68.0 65.0\n",
      "65.0 66.0\n",
      "65.0 66.0\n",
      "68.0 66.0\n",
      "65.0 66.0\n",
      "65.0 66.0\n",
      "68.0 66.0\n",
      "65.0 66.0\n",
      "66.0 65.0\n",
      "66.0 68.0\n",
      "68.0 65.0\n",
      "68.0 66.0\n",
      "68.0 66.0\n",
      "66.0 65.0\n",
      "66.0 58.0\n",
      "66.0 58.0\n",
      "68.0 58.0\n",
      "66.0 68.0\n",
      "68.0 65.0\n",
      "66.0 58.0\n",
      "66.0 68.0\n",
      "66.0 58.0\n",
      "66.0 65.0\n",
      "65.0 66.0\n",
      "66.0 68.0\n",
      "66.0 65.0\n",
      "66.0 68.0\n",
      "0.0 1.0\n",
      "68.0 65.0\n",
      "66.0 58.0\n",
      "66.0 68.0\n",
      "66.0 68.0\n",
      "66.0 68.0\n",
      "65.0 66.0\n",
      "65.0 66.0\n",
      "66.0 58.0\n",
      "66.0 68.0\n",
      "68.0 66.0\n",
      "65.0 66.0\n",
      "66.0 68.0\n",
      "68.0 65.0\n",
      "68.0 66.0\n",
      "68.0 66.0\n",
      "68.0 58.0\n",
      "65.0 66.0\n",
      "65.0 66.0\n",
      "66.0 65.0\n",
      "66.0 68.0\n",
      "68.0 66.0\n",
      "68.0 66.0\n",
      "66.0 65.0\n",
      "66.0 68.0\n",
      "66.0 68.0\n",
      "65.0 66.0\n",
      "66.0 68.0\n",
      "65.0 66.0\n",
      "66.0 58.0\n",
      "66.0 58.0\n",
      "66.0 58.0\n",
      "66.0 65.0\n",
      "65.0 66.0\n",
      "66.0 65.0\n",
      "68.0 66.0\n",
      "68.0 58.0\n",
      "68.0 66.0\n",
      "1.0 0.0\n",
      "65.0 66.0\n",
      "66.0 58.0\n",
      "65.0 66.0\n",
      "68.0 65.0\n",
      "66.0 65.0\n",
      "66.0 68.0\n",
      "68.0 66.0\n",
      "66.0 68.0\n",
      "68.0 66.0\n",
      "68.0 66.0\n",
      "65.0 66.0\n",
      "66.0 68.0\n",
      "66.0 68.0\n",
      "66.0 65.0\n",
      "65.0 66.0\n",
      "66.0 65.0\n",
      "68.0 66.0\n",
      "66.0 65.0\n",
      "66.0 68.0\n",
      "66.0 68.0\n",
      "66.0 58.0\n",
      "66.0 68.0\n",
      "68.0 65.0\n",
      "68.0 58.0\n",
      "65.0 66.0\n",
      "65.0 66.0\n",
      "65.0 66.0\n",
      "66.0 65.0\n",
      "65.0 66.0\n",
      "68.0 65.0\n",
      "66.0 68.0\n",
      "66.0 68.0\n",
      "68.0 66.0\n",
      "68.0 58.0\n",
      "68.0 66.0\n",
      "66.0 68.0\n",
      "66.0 68.0\n",
      "68.0 66.0\n",
      "68.0 58.0\n",
      "66.0 68.0\n",
      "65.0 66.0\n",
      "65.0 66.0\n",
      "68.0 66.0\n",
      "65.0 66.0\n",
      "66.0 68.0\n",
      "66.0 68.0\n",
      "66.0 58.0\n",
      "66.0 65.0\n",
      "66.0 68.0\n",
      "68.0 66.0\n",
      "68.0 65.0\n",
      "68.0 66.0\n",
      "68.0 66.0\n",
      "66.0 68.0\n",
      "65.0 66.0\n",
      "66.0 68.0\n",
      "65.0 66.0\n",
      "66.0 58.0\n",
      "66.0 68.0\n",
      "68.0 58.0\n",
      "68.0 66.0\n",
      "68.0 66.0\n",
      "66.0 65.0\n",
      "66.0 58.0\n",
      "66.0 68.0\n",
      "65.0 66.0\n",
      "66.0 68.0\n",
      "68.0 66.0\n",
      "68.0 65.0\n",
      "68.0 66.0\n",
      "68.0 58.0\n",
      "66.0 58.0\n",
      "66.0 65.0\n",
      "66.0 68.0\n",
      "68.0 65.0\n",
      "68.0 65.0\n",
      "66.0 68.0\n",
      "66.0 68.0\n",
      "68.0 66.0\n",
      "66.0 58.0\n",
      "66.0 65.0\n",
      "66.0 65.0\n",
      "66.0 58.0\n",
      "66.0 68.0\n",
      "65.0 66.0\n",
      "66.0 58.0\n",
      "68.0 66.0\n",
      "68.0 66.0\n",
      "68.0 66.0\n",
      "68.0 66.0\n",
      "0.8984517304189436\n"
     ]
    }
   ],
   "source": [
    "predictions = estimator.predict(x_test)\n",
    "sum = 0\n",
    "for i in range(len(y_test)):\n",
    "    if predictions[i] == y_test[i]:\n",
    "        sum += 1\n",
    "    else:\n",
    "        print(predictions[i], y_test[i])\n",
    "accuracy = sum / len(y_test)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-21 19:18:58.101736: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "549/549 [==============================] - 3s 5ms/step - loss: 1516.0127 - Accuracy: 0.0239\n",
      "Epoch 2/4\n",
      "549/549 [==============================] - 3s 5ms/step - loss: 1516.0126 - Accuracy: 0.0192\n",
      "Epoch 3/4\n",
      "549/549 [==============================] - 3s 5ms/step - loss: 1516.0114 - Accuracy: 0.0157\n",
      "Epoch 4/4\n",
      "549/549 [==============================] - 3s 5ms/step - loss: 1516.0126 - Accuracy: 0.0158\n"
     ]
    }
   ],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# Train the model\n",
    "model.fit(x_train, y_train, epochs=4, batch_size=32)\n",
    "\n",
    "# Save the model\n",
    "model.save('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 64)                4736      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 70)                4550      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 13,446\n",
      "Trainable params: 13,446\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 24/138 [====>.........................] - ETA: 0s - loss: 1532.9799 - Accuracy: 0.0143"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-21 19:15:04.344002: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "138/138 [==============================] - 1s 5ms/step - loss: 1543.8839 - Accuracy: 0.0159\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1543.8839111328125, 0.01593806967139244]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 54ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-21 19:15:08.286251: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(x_test[1:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.01436608 0.01463229 0.01376316 0.01421796 0.01378758 0.01428406\n",
      "  0.01380708 0.01440014 0.01369997 0.01416355 0.01501793 0.01424237\n",
      "  0.01383106 0.0141349  0.014016   0.01417218 0.01522212 0.01419538\n",
      "  0.01467267 0.01395234 0.01460596 0.0148426  0.01505581 0.01374258\n",
      "  0.01432052 0.01495502 0.01384656 0.01370651 0.01430485 0.01438976\n",
      "  0.01432353 0.01356148 0.01416743 0.0141808  0.0144723  0.01426448\n",
      "  0.01365536 0.0145434  0.01390234 0.0142574  0.01462263 0.01401307\n",
      "  0.01524819 0.01455383 0.01384162 0.01434676 0.01391233 0.0145729\n",
      "  0.01401076 0.01390359 0.01464595 0.01460167 0.01370955 0.01502277\n",
      "  0.0141082  0.01442356 0.01441614 0.01386539 0.01406827 0.01471683\n",
      "  0.01359903 0.01470423 0.01456719 0.01492687 0.0143537  0.01338557\n",
      "  0.01514377 0.01366953 0.01449761 0.014871  ]\n",
      " [0.01358154 0.0145574  0.01342274 0.01354806 0.0151034  0.01418611\n",
      "  0.01424117 0.0142363  0.01422978 0.01449606 0.01492848 0.01445444\n",
      "  0.01439432 0.01393763 0.01387919 0.01361272 0.01412704 0.01380546\n",
      "  0.01442172 0.01416775 0.01455196 0.01352635 0.01461517 0.01461463\n",
      "  0.01497549 0.01430017 0.01442231 0.01350061 0.01343756 0.01469586\n",
      "  0.01432521 0.01345374 0.01547276 0.01458596 0.01438089 0.01358049\n",
      "  0.01490142 0.01501024 0.01448537 0.01451068 0.01429361 0.01433971\n",
      "  0.01493267 0.01501874 0.01401163 0.01378534 0.0135377  0.01395634\n",
      "  0.01467665 0.01455624 0.01458874 0.01421165 0.01479546 0.01387\n",
      "  0.01445466 0.01467278 0.01458911 0.01281395 0.01429183 0.01474239\n",
      "  0.01437078 0.01465713 0.01374009 0.01516681 0.01479889 0.01292318\n",
      "  0.01420628 0.01449035 0.01439984 0.01442919]\n",
      " [0.01456528 0.0152367  0.01338359 0.01509317 0.01468033 0.01386539\n",
      "  0.01375322 0.01289238 0.01454616 0.01577542 0.01507988 0.01392859\n",
      "  0.01479394 0.01455309 0.01456714 0.01432802 0.01344491 0.01464909\n",
      "  0.01537726 0.01521754 0.01392209 0.01469935 0.01421933 0.01358214\n",
      "  0.01389191 0.01504804 0.0138907  0.0139322  0.01372591 0.01342197\n",
      "  0.01307666 0.0134535  0.01405435 0.01402426 0.01399576 0.01498482\n",
      "  0.0139047  0.01325666 0.01401544 0.01325558 0.01571122 0.01477391\n",
      "  0.01476088 0.0144048  0.01432254 0.0147479  0.01376883 0.01395846\n",
      "  0.01446245 0.01349835 0.01466655 0.01442906 0.01502006 0.01449578\n",
      "  0.01430143 0.01423714 0.01502529 0.01423679 0.01320757 0.01432033\n",
      "  0.01393356 0.0142986  0.01418446 0.01484586 0.01403835 0.0139155\n",
      "  0.01503369 0.01448059 0.0148338  0.01399984]\n",
      " [0.01452121 0.01481977 0.01478029 0.01289687 0.01451837 0.01302482\n",
      "  0.01343118 0.01298952 0.0147154  0.01370421 0.01500451 0.0133244\n",
      "  0.01300327 0.01405154 0.01421572 0.01350746 0.01487783 0.01381381\n",
      "  0.013852   0.01472208 0.01413855 0.01292343 0.01495066 0.0154574\n",
      "  0.01495963 0.01365827 0.01475623 0.01420143 0.01469688 0.0150574\n",
      "  0.01501533 0.01363419 0.01391092 0.01330627 0.01490337 0.01461105\n",
      "  0.01454436 0.01386955 0.01405368 0.01429531 0.01418895 0.01393331\n",
      "  0.01458188 0.01339558 0.01427864 0.01461484 0.01461654 0.01449194\n",
      "  0.01411753 0.01360349 0.01513657 0.01407631 0.01542258 0.01406848\n",
      "  0.01426874 0.01370696 0.015385   0.01468054 0.01465539 0.01488907\n",
      "  0.01484121 0.01407375 0.01354111 0.0141402  0.01479385 0.01451692\n",
      "  0.01437354 0.01517828 0.01486019 0.01485039]\n",
      " [0.01417229 0.0140365  0.01429109 0.01420292 0.01501105 0.01451591\n",
      "  0.01468409 0.014345   0.01451521 0.01409318 0.01456549 0.01441226\n",
      "  0.0141996  0.01406352 0.01452189 0.01490391 0.01484978 0.01450794\n",
      "  0.01353457 0.01412594 0.0149661  0.01302961 0.01400733 0.01511007\n",
      "  0.0140694  0.01363841 0.01483967 0.01407494 0.01367852 0.01400451\n",
      "  0.01495996 0.01450701 0.01419161 0.01401574 0.01412231 0.01413263\n",
      "  0.01490767 0.01507064 0.01409991 0.01420852 0.01390722 0.0142588\n",
      "  0.0141404  0.01362875 0.01556932 0.01422173 0.01391735 0.01370102\n",
      "  0.01475278 0.01526436 0.01427076 0.01397885 0.01388013 0.01376848\n",
      "  0.01475369 0.0144332  0.01416012 0.01408263 0.01434841 0.01420569\n",
      "  0.01414012 0.0142241  0.01419059 0.01367716 0.01400087 0.01503919\n",
      "  0.01459069 0.01417145 0.01351382 0.01402164]\n",
      " [0.01481806 0.01385701 0.01462528 0.01427726 0.0130719  0.01438854\n",
      "  0.01530371 0.0162673  0.01446529 0.01346273 0.01373803 0.0145895\n",
      "  0.01399874 0.01347424 0.01387321 0.0139485  0.01462223 0.01349902\n",
      "  0.01389797 0.01358238 0.01500823 0.01434778 0.01449776 0.01420045\n",
      "  0.01354827 0.0142061  0.01449227 0.01412726 0.01476362 0.01494412\n",
      "  0.01390269 0.0148603  0.01407793 0.0146078  0.01371019 0.01386343\n",
      "  0.01436062 0.01511523 0.01412596 0.01455658 0.01477245 0.0139561\n",
      "  0.01374144 0.01423067 0.01435701 0.01351441 0.01383279 0.0143935\n",
      "  0.01403298 0.01534128 0.01326837 0.01380733 0.01384772 0.01484606\n",
      "  0.01409394 0.01397601 0.01423756 0.01463171 0.01471918 0.01459517\n",
      "  0.01351418 0.01514624 0.01463245 0.01527664 0.01398015 0.01471409\n",
      "  0.01443131 0.01419182 0.01438017 0.0144598 ]\n",
      " [0.01429177 0.01412149 0.01400017 0.01406783 0.01524484 0.01463372\n",
      "  0.01461662 0.01402926 0.01446575 0.01436636 0.01406165 0.01466083\n",
      "  0.01438902 0.01373458 0.01444974 0.01429963 0.01433547 0.0144447\n",
      "  0.01395956 0.01370898 0.01448779 0.01353488 0.01437472 0.01492186\n",
      "  0.01425339 0.01408776 0.01455035 0.01399377 0.01359384 0.01390496\n",
      "  0.01435478 0.01425447 0.01444983 0.01437444 0.01506075 0.01418516\n",
      "  0.01531772 0.01490097 0.01478009 0.01415743 0.01412331 0.01430425\n",
      "  0.01417598 0.0144044  0.01466111 0.01389659 0.01399055 0.01362721\n",
      "  0.01487723 0.01476381 0.01375336 0.01402148 0.01418739 0.01381871\n",
      "  0.01478213 0.01510803 0.01439667 0.01341944 0.0138994  0.01429251\n",
      "  0.01448076 0.01439632 0.0138361  0.01433186 0.01465238 0.01400182\n",
      "  0.01401362 0.0143252  0.01411793 0.01391952]\n",
      " [0.01399479 0.01428479 0.01434412 0.01417058 0.01454729 0.01551369\n",
      "  0.01472107 0.01473721 0.01369709 0.01332    0.0149024  0.0144845\n",
      "  0.01398886 0.01403027 0.01407545 0.01425541 0.01469804 0.01457109\n",
      "  0.01386624 0.0136494  0.01411063 0.01351408 0.01505036 0.01469066\n",
      "  0.0144747  0.01450996 0.01462159 0.01425334 0.01380338 0.01420612\n",
      "  0.01487659 0.01390148 0.01499533 0.01451354 0.01492432 0.01303414\n",
      "  0.01509529 0.0153437  0.01411674 0.01485955 0.01376505 0.01368158\n",
      "  0.01438711 0.01452848 0.01479223 0.01332673 0.01410656 0.01296738\n",
      "  0.01499171 0.01514295 0.01361036 0.01404897 0.0134764  0.01336625\n",
      "  0.01449993 0.01462678 0.01389935 0.01414413 0.0143337  0.01492257\n",
      "  0.01361846 0.01505625 0.01372229 0.01505815 0.01433043 0.01361965\n",
      "  0.01463313 0.01396892 0.0138659  0.01476086]\n",
      " [0.01379895 0.01430887 0.01420938 0.01377975 0.01397148 0.01344115\n",
      "  0.0143568  0.01359457 0.01438633 0.01443892 0.01421948 0.01459288\n",
      "  0.01425196 0.01447151 0.01449837 0.01483743 0.01441107 0.01463899\n",
      "  0.01372852 0.01471264 0.01471121 0.01383975 0.01373737 0.01491082\n",
      "  0.01447459 0.01339882 0.01455056 0.01426961 0.01453138 0.01494682\n",
      "  0.01494078 0.01466719 0.01429171 0.01422708 0.01396561 0.01417863\n",
      "  0.01461604 0.01443632 0.0134616  0.01453273 0.01394247 0.0144462\n",
      "  0.01377424 0.0138734  0.01471503 0.01468277 0.01477018 0.01469074\n",
      "  0.01425899 0.01457326 0.01515005 0.01392076 0.01398701 0.01435679\n",
      "  0.01417937 0.01356889 0.01389378 0.01448695 0.01487317 0.01367756\n",
      "  0.01378493 0.01353512 0.01491632 0.01380234 0.0140034  0.01539579\n",
      "  0.01441179 0.0148699  0.01370212 0.01441895]]\n"
     ]
    }
   ],
   "source": [
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([47., 26., 32.,  8., 55., 42., 65., 34., 48.])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[1:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0q/8f0zskws27x_14w3qmfndjfw0000gn/T/ipykernel_32603/4022209231.py:4: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
      "  accuracy = np.sum(rounded_predictions == y_test[1:10]) / len(y_test[1:10])\n"
     ]
    }
   ],
   "source": [
    "# round the predictions\n",
    "rounded_predictions = np.round(predictions)\n",
    "# claculate the accuracy\n",
    "accuracy = np.sum(rounded_predictions == y_test[1:10]) / len(y_test[1:10])\n",
    "print(accuracy)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "138/138 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[39msum\u001b[39m \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m      4\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(y_test)):\n\u001b[0;32m----> 5\u001b[0m     \u001b[39mif\u001b[39;00m rounded_predictions[i] \u001b[39m==\u001b[39m y_test[i]:\n\u001b[1;32m      6\u001b[0m         \u001b[39msum\u001b[39m \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m      7\u001b[0m accuracy \u001b[39m=\u001b[39m \u001b[39msum\u001b[39m \u001b[39m/\u001b[39m \u001b[39mlen\u001b[39m(y_test)\n",
      "\u001b[0;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(x_test)\n",
    "rounded_predictions = np.round(predictions)\n",
    "sum = 0\n",
    "for i in range(len(y_test)):\n",
    "    if rounded_predictions[i] == y_test[i]:\n",
    "        sum += 1\n",
    "accuracy = sum / len(y_test)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "070cdce012dd41a01f1f0ff20239b474e092c7a2b169ddafdace8d691490e16c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
